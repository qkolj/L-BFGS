{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55210c2",
   "metadata": {},
   "source": [
    "# <center>L-BFGS метода оптимизације</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b1983f",
   "metadata": {},
   "source": [
    "L-BFGS (Limited-memory BFGS) је квази-Њутнова метода оптимизације другог реда заснована на методи BFGS (Broyden–Fletcher–Goldfarb–Shanno). Идеја L-BFGS метода је да се унапреди стандардна BFGS метода уклањањем потребе за складиштењем целокупне апроксимације инверза хесијана, уместо које се чува одређени број последњих разлика градијената и разлика решења из претходних корака, на основу којих се може ефикасним поступком апроксимирати производ $H_k^{-1}\\nabla f_k$. Наиме, BFGS метод оптимизације има следеће правило ажурирања текућег решења:\n",
    "\n",
    "$$x_{k+1} = x_{k} - \\alpha_k H_k^{-1} \\nabla f_k \\tag{1}$$\n",
    "\n",
    "при чему су $\\alpha_k$ корак, а $H_k^{-1}$ апроксимација инверза хесијана у $k$-тоj итерацији. $H_k^{-1}$ се ажурира према следећем правилу:\n",
    "\n",
    "$$H_{k+1}^{-1} = V_k^TH_k^{-1}V_k + \\rho_ks_ks_k^T \\tag{2}$$\n",
    "\n",
    "где су:\n",
    "\n",
    "$$\\rho_k = \\frac{1}{y_k^Ts_k},\\hspace{3em}V_k = I - \\rho_ky_ks_k^T, \\tag{3}$$\n",
    "\n",
    "$$s_k = x_{k+1} - x_k,\\hspace{3em}y_k = \\nabla f_{k+1} - \\nabla f_k. \\tag{4}$$\n",
    "\n",
    "Да би се избегло чување апроксимације инверза хесијана $H_k^{-1}$, која је у општем случају густа матрица, прибегава се чувању модификоване верзије $H_k^{-1}$ имплицитно, чувањем $m$ парова вектора $\\{s_i, y_i\\}$ добијених горепоменутим изразима (2)-(4) у последњих $m$ итерација. На основу вектора $\\{s_i, y_i\\}$ и $\\nabla f_k$, израчунава се производ $H_k^{-1}\\nabla f_k$ поступком који ће у наставку бити описан."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b40133",
   "metadata": {},
   "source": [
    "Наиме, у $k$-тој итерацији, текуће решење је $x_k$, и скуп парова вектора $\\{s_i, y_i\\}$ има вредности за $i = k - m, ... , k - 1$. Потребно је одабрати неку иницијалну апроксимацију инверза хесијана $H_k^0$, на основу које, узастопном применом правила (2), се добија следећи израз:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "H_k^{-1} & = (V_{k-1}^T\\cdots V_{k-m}^T)H_k^0(V_{k-m}\\cdots V_{k-1})\n",
    "\\\\&+ \\rho_{k-m}(V_{k-1}^T\\cdots V_{k-m+1}^T)s_{k-m}s_{k-m}^T(V_{k-m+1}\\cdots V_{k-1})\n",
    "\\\\&+ \\rho_{k-m+1}(V_{k-1}^T\\cdots V_{k-m+2}^T)s_{k-m+1}s_{k-m+1}^T(V_{k-m+2}\\cdots V_{k-1})\n",
    "\\\\&+ \\cdots\n",
    "\\\\&+ \\rho_{k-1}s_{k-1}s_{k-1}^T\n",
    "\\end{split}\n",
    "\\tag{5}\n",
    "\\end{equation}\n",
    "\n",
    "На основу израза (5), уз нешто алгебарског сређивања, природно произилази следећи алгоритам за рачунање $H_k^{-1}\\nabla f_k$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e345a41",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "&Улаз:\\hspace{1ex}текуће\\hspace{1ex}решење\\hspace{1ex}x_k,\\hspace{1ex}дужина\\hspace{1ex}''историје''\\hspace{1ex}m \\\\\n",
    "&Излаз:\\hspace{1ex}вредност\\hspace{1ex}производа\\hspace{1ex}H_k^{-1}\\nabla f_k \\\\\n",
    "&q \\leftarrow \\nabla f_k;\\\\\n",
    "&\\textbf{for}\\hspace{1ex}i = k-1,k-2,...,k-m \\\\\n",
    "&\\hspace{3em}\\alpha_i \\leftarrow \\rho_is_i^Tq; \\\\\n",
    "&\\hspace{3em}q \\leftarrow q - \\alpha_iy_i; \\\\\n",
    "&\\textbf{end}\\hspace{1ex}(\\textbf{for}) \\\\\n",
    "&r \\leftarrow H_k^0q; \\\\\n",
    "&\\textbf{for}\\hspace{1ex}i=k-m,k-m+1,...,k-1 \\\\\n",
    "&\\hspace{3em}\\beta \\leftarrow \\rho_iy_i^Tr; \\\\\n",
    "&\\hspace{3em}r \\leftarrow r + s_i(\\alpha_i - \\beta); \\\\\n",
    "&\\textbf{end}\\hspace{1ex}(\\textbf{for}) \\\\\n",
    "\\end{align*}\n",
    "\\tag{A1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46a9e6c",
   "metadata": {},
   "source": [
    "Треба још одлучити како се бира иницијална апроксимација хесијана $H_k^0$. Релативно једноставан метод који у пракси даје добре резултате је да се узима:\n",
    "\n",
    "$$H_k^0 = \\gamma_kI,\\hspace{3em}\\gamma_k = \\frac{s_{k-1}^Ty_{k-1}}{y_{k-1}^Ty_{k-1}} \\tag{6}$$\n",
    "\n",
    "Као и за стандардну BFGS методу, корак $\\alpha_k$ из правила ажурирања (1) бира се тако да задовољава (6) Вулф услове (енг. *Wolfe conditions*) или (7) строге Вулф услове (енг. *strong Wolfe conditions*):\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "f(x_k+\\alpha_kp_k) &\\leq f(x_k)+c_1\\alpha_k\\nabla f_k^Tp_k \\\\\n",
    "\\nabla f(x_k+\\alpha_kp_k)^Tp_k &\\geq c_2\\nabla f_k^Tp_k \\\\\n",
    "\\end{align*}\n",
    "\\tag{6}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "f(x_k+\\alpha_kp_k) &\\leq f(x_k)+c_1\\alpha_k\\nabla f_k^Tp_k \\\\\n",
    "\\nabla |f(x_k+\\alpha_kp_k)^Tp_k| &\\leq c_2|\\nabla f_k^Tp_k| \\\\\n",
    "\\end{align*}\n",
    "\\tag{7}\n",
    "$$\n",
    "\n",
    "где су $0 < c_1 < c_2 < 1$. У пракси се често узимају вредности $c_1=10^{-4}$ и $c_2=0.9$. Први услов у (6) и (7) је тзв. Армихо услов (енг. *Armijo condition*) који гарантује пад вредности циљне функције довољан за конвергенцију, док је други услов тзв. услов кривине (енг. *curvature condition*) који елими\\-нише премале кораке. Специјално, код строгих Вулф услова, елиминишу се тачке које нису у широј околини локалног минимума или стационарне тачке.\n",
    "\n",
    "Алгоритам за налажење корака $\\alpha_k$ који испуњава строге Вулф услове извршава се у два корака: прво се проналази интервал који садржи прихватљиве вредности корака, а затим се (алгоритмом *zoom*) проналази задовољавајућа вредност корака у оквиру тог интервала."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaeb07e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "&Улаз:\\hspace{1ex}функција\\hspace{1ex}\\phi(\\alpha),\\hspace{1ex}параметри\\hspace{1ex}c_1\\hspace{1ex}и\\hspace{1ex}c_2 \\\\\n",
    "&Излаз:\\hspace{1ex}корак\\hspace{1ex}\\alpha_*\\hspace{1ex}који\\hspace{1ex}испуњава\\hspace{1ex}строге\\hspace{1ex}Вулф\\hspace{1ex}услове\\hspace{1ex}(7) \\\\\n",
    "&\\alpha_0 \\leftarrow 0 \\\\\n",
    "&одабрати\\hspace{1ex}\\alpha_{max} > 0\\hspace{1ex}и\\hspace{1ex}\\alpha_1 \\in (0,\\alpha_{max}); \\\\\n",
    "&i \\leftarrow 1; \\\\\n",
    "&\\textbf{repeat} \\\\\n",
    "&\\hspace{3em}израчунати\\hspace{1ex}\\phi(\\alpha_i); \\\\\n",
    "&\\hspace{3em}\\textbf{if}\\hspace{1ex}\\phi(\\alpha_i) > \\phi(0) + c_1\\alpha_i\\phi'(0)\\hspace{1ex}or\\hspace{1ex}[\\phi(\\alpha_i) \\geq \\phi(\\alpha_{i-1})\\hspace{1ex}and\\hspace{1ex}i > 1] \\\\\n",
    "&\\hspace{6em}\\alpha_* \\leftarrow \\textbf{zoom}(\\alpha_{i-1},\\alpha_{i}); \\\\\n",
    "&\\hspace{6em}\\textbf{stop}\\\\\n",
    "&\\hspace{3em}израчунати\\hspace{1ex}\\phi'(\\alpha_i); \\\\\n",
    "&\\hspace{3em}\\textbf{if}\\hspace{1ex}|\\phi'(\\alpha_i)| \\leq -c_2\\phi'(0) \\\\\n",
    "&\\hspace{6em}\\alpha_* \\leftarrow \\alpha_{i}; \\\\\n",
    "&\\hspace{6em}\\textbf{stop}\\\\\n",
    "&\\hspace{3em}\\textbf{if}\\hspace{1ex}\\phi'(\\alpha_i) \\geq 0 \\\\\n",
    "&\\hspace{6em}\\alpha_* \\leftarrow \\textbf{zoom}(\\alpha_{i},\\alpha_{i-1}); \\\\\n",
    "&\\hspace{6em}\\textbf{stop}\\\\\n",
    "&\\hspace{3em}одабрати\\hspace{1ex}\\alpha_{i+1} \\in (\\alpha_i,\\alpha_{max}); \\\\\n",
    "&\\hspace{3em}i \\leftarrow i + 1; \\\\\n",
    "&\\textbf{end}\\hspace{1ex}(\\textbf{repeat})\n",
    "\\end{align*}\n",
    "\\tag{A2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47831c36",
   "metadata": {},
   "source": [
    "где је $\\phi(\\alpha) = f(x_k + \\alpha p_k)$. Следи опис алгоритма $\\textbf{zoom}(\\alpha_{lo}, \\alpha_{hi})$ коришћеног у алгоритму линијске претраге (А2):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5bef0e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "&Улаз:\\hspace{1ex}функција\\hspace{1ex}\\phi(\\alpha),\\hspace{1ex}границе\\hspace{1ex}интервала\\hspace{1ex}\\alpha_{lo}\\hspace{1ex}и\\hspace{1ex}\\alpha_{hi}\\\\\n",
    "&Излаз:\\hspace{1ex}задовољавајући\\hspace{1ex}корак\\hspace{1ex}\\alpha_*\\hspace{1ex}из\\hspace{1ex}интервала\\hspace{1ex}[\\alpha_{lo},\\alpha_{hi}]\\\\\n",
    "&\\textbf{repeat} \\\\\n",
    "&\\hspace{3em}некако\\hspace{1ex}одабрати\\hspace{1ex}корак\\hspace{1ex}\\alpha_j\\hspace{1ex}између\\hspace{1ex}\\alpha_{lo}\\hspace{1ex}и\\hspace{1ex}\\alpha_{hi}\\hspace{1ex}(на\\hspace{1ex}пример,\\hspace{1ex}бисекцијом); \\\\\n",
    "&\\hspace{3em}израчунати\\hspace{1ex}\\phi(\\alpha_j); \\\\\n",
    "&\\hspace{3em}\\textbf{if}\\hspace{1ex}\\phi(\\alpha_j)>\\phi(0)+c_1\\alpha_j\\phi'(0)\\hspace{1ex}or\\hspace{1ex}\\phi(\\alpha_j) \\geq \\phi(\\alpha_{lo}) \\\\\n",
    "&\\hspace{6em}\\alpha_{hi} \\leftarrow \\alpha_j; \\\\\n",
    "&\\hspace{3em}\\textbf{else} \\\\\n",
    "&\\hspace{6em}израчунати\\hspace{1ex}\\phi'(\\alpha_j); \\\\\n",
    "&\\hspace{6em}\\textbf{if}\\hspace{1ex}|\\phi'(\\alpha_j)|\\leq -c_2\\phi'(0) \\\\\n",
    "&\\hspace{9em}\\alpha_* \\leftarrow \\alpha_j; \\\\\n",
    "&\\hspace{9em}\\textbf{stop} \\\\\n",
    "&\\hspace{6em}\\textbf{if}\\hspace{1ex}\\phi'(\\alpha_j)(\\alpha_{hi}-\\alpha_{lo}) \\geq 0 \\\\\n",
    "&\\hspace{9em}\\alpha_{hi} \\leftarrow \\alpha_{lo}; \\\\\n",
    "&\\hspace{6em}\\alpha_{lo} \\leftarrow \\alpha_{j}; \\\\\n",
    "&\\textbf{end}\\hspace{1ex}(\\textbf{repeat}) \\\\\n",
    "\\end{align*}\n",
    "\\tag{A3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c925f1cc",
   "metadata": {},
   "source": [
    "Пошто су алгоритмима (А1)-(А3) дати сви потребни помоћни алгоритми, сада се коначно може дати и сам алгоритам L-BFGS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ec91b2",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "&Улаз:\\hspace{1ex}циљна\\hspace{1ex}функција\\hspace{1ex}f,\\hspace{1ex}њен\\hspace{1ex}градијент\\hspace{1ex}\\nabla f,\\hspace{1ex}почетна\\hspace{1ex}тачка\\hspace{1ex}x_0,\\hspace{1ex}дужина\\hspace{1ex}''историје''\\hspace{1ex}m,\\hspace{1ex}параметар\\hspace{1ex}конвергенције\\hspace{1ex}\\epsilon \\\\\n",
    "&Излаз:\\hspace{1ex}апроксимација\\hspace{1ex}минимума\\hspace{1ex}x^* \\\\\n",
    "&k \\leftarrow 0; \\\\\n",
    "&\\textbf{repeat} \\\\\n",
    "&\\hspace{3em}израчунати\\hspace{1ex}H_k^0\\hspace{1ex}по\\hspace{1ex}правилу\\hspace{1ex}(6); \\\\\n",
    "&\\hspace{3em}израчунати\\hspace{1ex}p_k \\leftarrow -H_k^{-1}\\nabla f_k\\hspace{1ex}алгоритмом\\hspace{1ex}(А1); \\\\\n",
    "&\\hspace{3em}израчунати\\hspace{1ex}x_{k+1} \\leftarrow x_k + \\alpha_k p_k\\hspace{1ex}где\\hspace{1ex}је\\hspace{1ex}\\alpha_k\\hspace{1ex}добијено\\hspace{1ex}применом\\hspace{1ex}алгоритама\\hspace{1ex}(А2)\\hspace{1ex}и\\hspace{1ex}(А3); \\\\\n",
    "&\\hspace{3em}\\textbf{if}\\hspace{1ex}||\\nabla f_{k+1} - \\nabla f_k|| < \\epsilon \\\\\n",
    "&\\hspace{6em}x^* \\leftarrow x_{k+1}; \\\\\n",
    "&\\hspace{6em}\\textbf{stop} \\\\\n",
    "&\\hspace{3em}\\textbf{if}\\hspace{1ex}k > m \\\\\n",
    "&\\hspace{6em}обрисати\\hspace{1ex}пар\\hspace{1ex}вектора\\hspace{1ex}\\{s_{k-m},y_{k-m}\\}\\hspace{1ex}из\\hspace{1ex}меморије; \\\\\n",
    "&\\hspace{3em}израчунати\\hspace{1ex}s_k \\leftarrow x_{k+1}-x_k, y_k = \\nabla f_{k+1} - \\nabla f_k; \\\\\n",
    "&\\hspace{3em}k \\leftarrow k + 1; \\\\\n",
    "&\\textbf{end}\\hspace{1ex}(\\textbf{repeat}) \\\\\n",
    "\\end{align*}\n",
    "\\tag{A4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185ba0cd",
   "metadata": {},
   "source": [
    "## <center>Имплементација L-BFGS метода оптимизацијe <br/> у програмском језику Python</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d85f84ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d465f31b",
   "metadata": {},
   "source": [
    "Алгоритам (А2) имплементира следећа Python функција:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5ab83bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wolfe_line_search(f, grad, x, p, max_iter=100, c1=10**-4, c2=0.9, alpha_1=1.0, alpha_max=1000):\n",
    "        \n",
    "    def phi(alpha):\n",
    "        return f(x + alpha * p)\n",
    "\n",
    "    def phi_grad(alpha):\n",
    "        return np.dot(grad(x + alpha * p).T, p)\n",
    "\n",
    "    alpha_i_1 = 0\n",
    "    alpha_i = alpha_1\n",
    "\n",
    "    for i in range(1, max_iter + 1):\n",
    "        phi_alpha_i = phi(alpha_i)\n",
    "        if (phi_alpha_i > phi(0) + c1 * alpha_i * phi_grad(0)) or (i > 1 and phi_alpha_i >= phi(alpha_i_1)):\n",
    "            return zoom(phi, phi_grad, alpha_i_1, alpha_i, c1, c2)\n",
    "        \n",
    "        phi_grad_alpha_i = phi_grad(alpha_i)\n",
    "        if np.abs(phi_grad_alpha_i) <= -c2 * phi_grad(0):\n",
    "            return alpha_i\n",
    "        if phi_grad_alpha_i >= 0:\n",
    "            return zoom(phi, phi_grad, alpha_i, alpha_i_1, c1, c2)\n",
    "        alpha_i_1 = alpha_i\n",
    "        alpha_i = min(2 * alpha_i, alpha_max)\n",
    "\n",
    "    if i == max_iter:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817c4ebf",
   "metadata": {},
   "source": [
    "Осим дефинисања функције $\\phi$ и $\\phi'$ преко прослеђене циљне функције и њеног градијента, функција `wolfe_line_search` прати алгоритам (А2) готово линију по линију. Битно је приметити да се за $\\alpha_1$ увек узима вредност 1 која ће сигурно бити у интервалу $(0, \\alpha_{max})$, као и да се за наредни корак $\\alpha_{i+1}$ узима дупло већа вредност (уколико не премашује $\\alpha_{max}$).\n",
    "\n",
    "Следећа Python функција имплементира помоћну процедуру `zoom` дату алгоритмом (А3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90fc095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom(phi, phi_grad, alpha_lo, alpha_hi, c1, c2, max_iter=100):\n",
    "    i = 0\n",
    "    while True:\n",
    "        alpha_j = (alpha_lo + alpha_hi) / 2.0\n",
    "        phi_alpha_j = phi(alpha_j)\n",
    "\n",
    "        if (phi_alpha_j > phi(0) + c1 * alpha_j * phi_grad(0)) or (phi_alpha_j >= phi(alpha_lo)):\n",
    "            alpha_hi = alpha_j\n",
    "        else:\n",
    "            phi_grad_alpha_j = phi_grad(alpha_j)\n",
    "            if np.abs(phi_grad_alpha_j) <= -c2 * phi_grad(0):\n",
    "                return alpha_j\n",
    "            if phi_grad_alpha_j * (alpha_hi - alpha_lo) >= 0:\n",
    "                alpha_hi = alpha_lo\n",
    "            alpha_lo = alpha_j\n",
    "        i += 1\n",
    "        if i >= max_iter:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82f33da",
   "metadata": {},
   "source": [
    "Функција `zoom` такође прати алгоритам (А3) линију по линију, једина имплементациона одлука је бирање $\\alpha_j$ простом бисекцијом интервала. \n",
    "\n",
    "Коначно, Python функција `lbfgs` имплементира L-BFGS метод оптимизације описан алгоритмом (А4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca73a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbfgs(f, grad, x0, eps=1e-4, max_iter=1000, history=10):\n",
    "    \n",
    "    n = len(x0)\n",
    "    \n",
    "    def two_loop_rec(x, m):\n",
    "        q = grad(x)\n",
    "        k = S.shape[0]\n",
    "        rhos = np.zeros(k)\n",
    "        alphas = np.zeros(k)\n",
    "        beta = 0\n",
    "        for i in range(k - 1, -1, -1):\n",
    "            rhos[i] = np.dot(Y[i].T, S[i]) ** -1\n",
    "            alphas[i] = np.dot(S[i].T, q) * rhos[i]\n",
    "            q = q - alphas[i] * Y[i]\n",
    "        if k > 0:\n",
    "            gamma_k = np.dot(S[k - 1].T, Y[k - 1]) / np.dot(Y[k - 1], Y[k - 1])\n",
    "            H_k0 = np.diag(gamma_k * np.ones(n))\n",
    "        else:\n",
    "            H_k0 = np.diag(np.ones(n))\n",
    "        r = np.dot(H_k0, q)\n",
    "        for i in range(k):\n",
    "            beta = rhos[i] * np.dot(Y[i].T, r)\n",
    "            r = r + S[i] * (alphas[i] - beta)\n",
    "        \n",
    "        return r\n",
    "    \n",
    "    S = np.empty([0, n])\n",
    "    Y = np.empty([0, n])\n",
    "    x_old = x0\n",
    "    \n",
    "    for k in range(1, max_iter + 1):\n",
    "        p_k = -two_loop_rec(x_old, history)\n",
    "        alpha_k = wolfe_line_search(f, grad, x_old, p_k)\n",
    "        \n",
    "        if alpha_k is None:\n",
    "            print(\"Wolfe line search did not converge\")\n",
    "            return x_old, k\n",
    "        \n",
    "        x_new = x_old + alpha_k * p_k\n",
    "        \n",
    "        grad_diff = grad(x_new) - grad(x_old)\n",
    "        if np.linalg.norm(grad_diff) < eps:\n",
    "            break\n",
    "        \n",
    "        if k > history:\n",
    "            S = S[1:]\n",
    "            Y = Y[1:]\n",
    "        S = np.append(S, [x_new - x_old], axis=0)\n",
    "        Y = np.append(Y, [grad_diff], axis=0)\n",
    "        x_old = x_new\n",
    "        \n",
    "    if k == max_iter:\n",
    "        print(\"Optimization did not converge\")\n",
    "    else:\n",
    "        print(\"Optimization converged in {} steps\".format(k))\n",
    "        \n",
    "    return x_new, k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889a6da7",
   "metadata": {},
   "source": [
    "Функција `two_loop_rec` имплементира поступак из алгоритма (А1) за рачунање производа $H_k^{-1}\\nabla f_k$, док низови $S$ и $Y$ представљају $\\{s_i,y_i\\}$, то јест, разлике решења и градијената из претходних корака.\n",
    "\n",
    "Сада ће бити демонстрирано коришћење имплементиране методе оптимизације на функцији $f(x_0, x_1) = 2x_0^2 + 3x_1^2 +4\\sin{x_0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc0582aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 2 * x[0]**2 + 3 * x[1]**2 + 4 * np.sin(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be9ed46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_f(x):\n",
    "    return np.array([4 * x[0] + 4 * np.cos(x[0]), 6 * x[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "055b7498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization converged in 7 steps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-7.39085133e-01,  1.45057323e-10]), 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbfgs(f, grad_f, np.array([1, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d5ab75",
   "metadata": {},
   "source": [
    "Провера добијеног резултата коришћењем имплементације из библиотеке `scipy`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57edcf98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: -1.6019544484516701\n",
       " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([4.82010287e-06, 1.14993299e-06])\n",
       "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "     nfev: 8\n",
       "      nit: 6\n",
       "     njev: 8\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([-7.39084413e-01,  1.91655499e-07])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize.minimize(f, np.array([1,1]), method='L-BFGS-B', jac=grad_f, options={'maxcor':10, 'gtol':1e-4})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a6fb03",
   "metadata": {},
   "source": [
    "## <center>Тестирање ове имплементације метода L-BFGS <br/> над неким проблемима из скупа CUTEst</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82633ee6",
   "metadata": {},
   "source": [
    "CUTEst (Constrained and Unconstrained Testing Enviorment with safe threads) представља трећу по реду (после CUTEr) итерацију оргиналног CUTE окружења за тестирање оптимизационог софтвера. Оно садржи значајну количину разноврсних проблема који се користе за тестирање исправности имплементације и анализу перформанси оптимизационих алгоритама. У овом делу рада ће ова горепредстављена имплементација L-BFGS методе оптимизације бити упоређена са библиотичком имплементацијом из библиотеке `scipy`, као и са имплементацијом класичне Њутнове методе из исте библиотеке над неким од проблема из скупа CUTEst.\n",
    "\n",
    "За програмски језик Python постоји интерфејс који омогућава коришћење CUTEst проблема који су иначе везани за програмске језике Fortran и MATLAB. Тај интерфејс имплементира библиотека `pycutest`. Нажалост, због комплексног процеса инсталације ове библиотеке, није могуће једноставно инсталирати ову библиотеку у оквиру Anaconda окружења. Због тога, поменуто тестирање биће изведено у оквиру датотеке `cutest_tests.py` која се може пронаћи у оквиру овог репозиторијума, а овде ће резултати бити приказани и прокоментарисани. Резултати овог тестирања могу се поновити једноставним покретањем поменутог скрипта на рачунару са правилно инсталираном библиотеком `pycutest`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df0858f",
   "metadata": {},
   "source": [
    "У следећој табели могу се видети називи и број променљивих у оквиру проблема који ће бити коришћени у тестирању:\n",
    "\n",
    "|Назив проблема|Број променљивих|\n",
    "|---|---|\n",
    "|BOX|10000|\n",
    "|DIXMAANL|1500|\n",
    "|EIGENALS|110|\n",
    "|FREUROTH|1000|\n",
    "|TRIDIA|1000|\n",
    "|VAREIGVL|5000|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc5e828",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
